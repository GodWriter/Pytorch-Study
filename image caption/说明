Image Captioning:
  Image caption的目标是将给定的一张图转换成自然语言的描述，我们常常使用Encoder-Decoder结构来完成这项任务，图片的encoder是一个CNN。在这个
教程里，我们使用在图片分类数据集ILSVRC-2012-CLS上预训练过的resnet-152模型,decoder是一个LSTM网络。

Training phase
  在encoder部分，预训练好的CNN从给定的图片中抽取特征向量，并且特征向量将会被线性转换成和LSTM输入维度相同的维度。在decoder部分，源文本和目标
文本已经预先定义好了。举个例子，如果图片的描述是"Giraffes standing next to each other"，则源序列是一个这样子的集合['<start>', 'Giraffes',
'standing', 'next', 'to', 'each', 'other']，目标序列是集合['Giraffes', 'standing', 'next','to', 'each', 'other', '<end>']。使用
这些源序列和目标序列以及特征向量，LSTM decoder将会被训练成一个基于特征向量的语言模型。

Test phase
  在test phase中，encoder部分几乎和training phase一致，唯一的区别就是将会使用batchnorm来移动平均值和方差，从而去取代小批量统计数据，这个
简单使用encoder.eval()就可以办到了。在decoder部分，test phase和training phase有很大的不同。在test phase中，LSTM decoder看不到图片的
描述。为了处理这个问题，LSTM将前一步生成的单词作为下一步输入的输入值，这个可以使用一个for-loop来应用。

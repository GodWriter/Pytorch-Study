import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from torch.autograd import Variable

#global parameters
input_size = 1 #输入神经元个数
output_size=  1 #输出神经元个数
num_epochs = 1000 #训练轮数
learning_rate = 0.001 #学习率

#Toy Dataset
x_train = np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]],dtype=np.float32) #定义了一个有10个数据的训练集
y_train = np.array([[1],[3],[5],[7],[9],[11],[13],[15],[17],[19]],dtype=np.float32) #10个数据的训练集的输出值

#Linear Regression Module
class LinearRegression(nn.Module): #继承nn.Module
    def __init__(self, input_size, output_size):
        super(LinearRegression, self).__init__() #继承父类
        self.linear = nn.Linear(input_size, output_size) #构造线性模型，输入为1个神经元，输出也为1个神经元
        
    def forward(self, x):
        out = self.linear(x) #定义前向传播，就是一个线性全连接
        return out #返回输出结果
    
model = LinearRegression(input_size, output_size) #实例一个模型

#Loss and Optimizer
criterion = nn.MSELoss() #定义损失函数
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) #定义优化器，采用随机梯度下降

#Train the Model 
for epoch in range(num_epochs): #开始训练，一共1000轮
    #Convert numpy array to torch Variable
    inputs = Variable(torch.from_numpy(x_train)) #将为numpy类型的数据集转化为tensor
    targets = Variable(torch.from_numpy(y_train)) #将为numpy类型的数据集对应的标签转化为tensor
    
    #Forward + Backward + Optimize
    optimizer.zero_grad() #梯度清零
    outputs = model(inputs) #前相传播，得到输出output
    loss = criterion(outputs, targets) #计算损失
    loss.backward() #反传播
    optimizer.step() #开始优化
    
    if(epoch+1)%5 == 0: #每训练5轮，进行一次输出，看一下损失率
        print('Epoch [%d/%d], Loss:%.4f'%(epoch+1, num_epochs, loss.data[0]))
        
#Plot the graph
predicted = model(Variable(torch.from_numpy(x_train))).data.numpy() #将训练数转化为预测值
plt.plot(x_train, y_train, 'ro', label='Original data') #将训练数据和其对应的返回值画图
plt.plot(x_train, predicted, label='Fitted line') #将预测曲线画出
plt.legend()
plt.show()

‘’‘
Notes:
  这是一个简洁又很经典的模型，只用两个神经元模拟了一个线性回归模型y=2x-1，通过修改num_epochs(训练轮数).我们可以清晰
的看出我们的预测曲线正在慢慢开始拟合我们的正确值，说明我们的梯度下降是有效的参数优化方法。我尝试着想打出linear.weigth
和linear.bias,但是失败了，应该是python没学到家的表现。
  不管怎么样，这个例子给的启发还是很大的。
’‘’
